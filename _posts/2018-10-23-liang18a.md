---
title: GPU-Accelerated Robotic Simulation for Distributed Reinforcement Learning
abstract: 'Most Deep Reinforcement Learning (Deep RL) algorithms require a prohibitively
  large number of training samples for learning complex tasks. Many recent works on
  speeding up Deep RL have focused on distributed training and simulation. While distributed
  training is often done on the GPU, simulation is not. In this work, we propose using
  GPU-accelerated RL simulations as an alternative to CPU ones. Using NVIDIA Flex,
  a GPU-based physics engine, we show promising speed-ups of learning various continuous-control,
  locomotion tasks. With one GPU and CPU core, we are able to train the Humanoid running
  task in less than 20 minutes, using 10-1000x fewer CPU cores than previous works.
  We also demonstrate the scalability of our simulator to multi-GPU settings to train
  more challenging locomotion tasks. '
keywords: " Deep Reinforcement Learning, GPU Acceleration, Simulation"
layout: inproceedings
series: Proceedings of Machine Learning Research
id: liang18a
month: 0
tex_title: GPU-Accelerated Robotic Simulation for Distributed Reinforcement Learning
firstpage: 270
lastpage: 282
page: 270-282
order: 270
cycles: false
bibtex_author: Liang, Jacky and Makoviychuk, Viktor and Handa, Ankur and Chentanez,
  Nuttapong and Macklin, Miles and Fox, Dieter
author:
- given: Jacky
  family: Liang
- given: Viktor
  family: Makoviychuk
- given: Ankur
  family: Handa
- given: Nuttapong
  family: Chentanez
- given: Miles
  family: Macklin
- given: Dieter
  family: Fox
date: 2018-10-23
address: 
publisher: PMLR
container-title: Proceedings of The 2nd Conference on Robot Learning
volume: '87'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 10
  - 23
pdf: http://proceedings.mlr.press/v87/liang18a/liang18a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
