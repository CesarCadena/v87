---
title: Including Uncertainty when Learning from Human Corrections
abstract: 'It is difficult for humans to efficiently teach robots how to correctly
  perform a task. One intuitive solution is for the robot to iteratively learn the
  human’s preferences from corrections, where the human improves the robot’s current
  behavior at each iteration. When learning from corrections, we argue that while
  the robot should estimate the most likely human preferences, it should also know
  what it does not know, and integrate this uncertainty as it makes decisions. We
  advance the state-of-the-art by introducing a Kalman filter for learning from corrections:
  this approach obtains the uncertainty of the estimated human preferences. Next,
  we demonstrate how the estimate uncertainty can be leveraged for active learning
  and risk-sensitive deployment. Our results indicate that obtaining and leveraging
  uncertainty leads to faster learning from human corrections. '
keywords: " human-robot interaction (HRI), inverse reinforcement learning (IRL)"
layout: inproceedings
series: Proceedings of Machine Learning Research
id: losey18a
month: 0
tex_title: Including Uncertainty when Learning from Human Corrections
firstpage: 123
lastpage: 132
page: 123-132
order: 123
cycles: false
bibtex_author: Losey, Dylan P. and O'Malley, Marcia K.
author:
- given: Dylan P.
  family: Losey
- given: Marcia K.
  family: O’Malley
date: 2018-10-23
address: 
publisher: PMLR
container-title: Proceedings of The 2nd Conference on Robot Learning
volume: '87'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 10
  - 23
pdf: http://proceedings.mlr.press/v87/losey18a/losey18a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
